{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0d0728",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from langchain_huggingface import HuggingFacePipeline\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcef270",
   "metadata": {},
   "source": [
    "### Step 1: Imports etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a62cfc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = os.path.join(os.getcwd(), \"ori_pqal.json\")\n",
    "tmp_data = pd.read_json(json_path).T\n",
    "\n",
    "# some labels have been defined as \"maybe\", only keep the yes/no answers\n",
    "tmp_data = tmp_data[tmp_data.final_decision.isin([\"yes\", \"no\"])]\n",
    "\n",
    "\n",
    "documents = pd.DataFrame({\"abstract\": tmp_data.apply(lambda row: (\" \").join(row.CONTEXTS+[row.LONG_ANSWER]), axis=1),\n",
    "             \"year\": tmp_data.YEAR})\n",
    "questions = pd.DataFrame({\"question\": tmp_data.QUESTION,\n",
    "             \"year\": tmp_data.YEAR,\n",
    "             \"gold_label\": tmp_data.final_decision,\n",
    "             \"gold_context\": tmp_data.LONG_ANSWER,\n",
    "             \"gold_document_id\": documents.index})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae56bb3f",
   "metadata": {},
   "source": [
    "### Step 2: Configuring LangChainLM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e1a7fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, how are you? Hello! I'm just a computer program, so I don't have feelings like humans do. But thank you for asking me how I am!\n",
      "\n",
      "I'm functioning normally and ready to assist you with any questions or tasks you might have. How can I help you today?\n",
      "\n",
      "If you need anything specific, feel free to ask. I'll do my best to provide accurate information based on the knowledge available in my database. Is there something particular you're interested in learning about or discussing? I'd be happy to talk about various topics if that would suit your needs better than answering general questions. Let me know! Hi there! How are you feeling today? As an AI language model, I don't have feelings, but I'm here and ready to assist you with any questions or tasks you may have. How can I help you today? If you want to chat about a different topic or need more personalized support, let me know what interests you, and we can dive deeper into it. What's been\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Configure LangChainLM\n",
    "# Choose a model from Hugging Face, prio training speed\n",
    "lm = HuggingFacePipeline.from_model_id(\n",
    "    model_id=\"Qwen/Qwen2.5-1.5B-Instruct\",\n",
    "    task=\"text-generation\",\n",
    "    model_kwargs={\n",
    "        \"torch_dtype\": \"auto\",\n",
    "        \"device_map\": \"auto\"\n",
    "        },\n",
    "    pipeline_kwargs={\n",
    "        \"max_new_tokens\": 200,\n",
    "        \"temperature\": 0.7,\n",
    "        \"top_p\": 0.95\n",
    "    }\n",
    ")\n",
    "\n",
    "response = lm.invoke(\"Hello, how are you?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94943af",
   "metadata": {},
   "source": [
    "### Step 3: Setup the document database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5469ac5",
   "metadata": {},
   "source": [
    "3.1 Downloading the embeddding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "770e1b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08204815536737442, 0.03605547919869423, -0.0038928501307964325, -0.004881061147898436, 0.02565111219882965, -0.05714341625571251, 0.012191585265100002, 0.004678942263126373, 0.03494987264275551, -0.022421881556510925, -0.008005267940461636, -0.10935357213020325, 0.022724749520421028, -0.02932085283100605, -0.043522052466869354, -0.120241180062294, -0.0008486059959977865, -0.018150174990296364, 0.05612955987453461, 0.003085269359871745, 0.0023364077787846327, -0.01683926209807396, 0.06362466514110565, -0.023660244420170784, 0.031493496149778366, -0.034797973930835724, -0.02054883912205696, -0.002791013801470399, -0.011037996038794518, -0.03612670674920082, 0.05414110794663429, -0.03661714494228363, -0.0250086709856987, -0.03817040100693703, -0.04960361495614052, -0.015148145146667957, 0.021315045654773712, -0.012740401551127434, 0.07670092582702637, 0.044355761259794235, -0.010834852233529091, -0.029759952798485756, -0.016970504075288773, -0.02469179406762123, 0.008087115362286568, 0.043587666004896164, 0.00717752194032073, 0.07550125569105148, 0.032806675881147385, -0.06204643473029137, 0.06677896529436111, 0.02709132432937622, -0.045689474791288376, -0.03144115209579468, -0.03115527145564556, 0.09153680503368378, -0.0017882139654830098, -0.011282645165920258, 0.03649934381246567, 0.05692708119750023, 0.0023000240325927734, -0.037750571966171265, -0.015484727919101715, 0.052391454577445984, 0.06036439165472984, -0.01664833351969719, 0.008809962309896946, -0.006622231099754572, -0.10629703104496002, 0.0017158882692456245, -0.048305828124284744, -0.029768720269203186, 0.004325565882027149, -0.08567408472299576, 0.06620795279741287, -0.05518351495265961, -0.11332663148641586, 0.05084018036723137, -0.009317242540419102, 0.006006685085594654, 0.021012742072343826, -0.02251548506319523, 0.0004727075865957886, 0.05638979375362396, 0.045443471521139145, -0.00527753634378314, 0.09359361976385117, 0.0274602472782135, 0.02944197691977024, -0.04569662734866142, -0.048944346606731415, 0.0013615054776892066, -0.012853392399847507, 0.0798071101307869, -0.11903543770313263, 0.06876882165670395, -0.02271832525730133, 0.044857025146484375, -0.08129200339317322, 0.044057831168174744, 0.002956320298835635, 0.017621006816625595, 0.08311302214860916, -0.018054965883493423, -0.04792356863617897, 0.0586671307682991, 0.006246435455977917, -0.01465682778507471, -0.007337239105254412, -0.07807914167642593, -0.10076918452978134, -0.0335267037153244, -0.0009018707205541432, -0.051131151616573334, 0.027221743017435074, 0.07086152583360672, 0.047401703894138336, -0.10456681251525879, 0.004401095677167177, -0.028793802484869957, -0.01835579425096512, -0.05058590695261955, -0.031541887670755386, -0.009517708793282509, -0.06064470484852791, 0.02116391621530056, -0.046602193266153336, -7.755117533354679e-33, -0.031296245753765106, 0.056345053017139435, 0.07738031446933746, 0.06391442567110062, -0.046647172421216965, -0.007570474874228239, -0.0553264319896698, 0.04027755558490753, -0.03152395784854889, -0.007102961651980877, 0.03959237039089203, -0.131711944937706, -0.06614520400762558, 0.021774960681796074, 0.09698937088251114, 0.011799278669059277, 0.08900413662195206, 0.034685928374528885, -0.04387180507183075, -0.00016681989654898643, 0.014680800959467888, -0.0027093326207250357, -0.0033176278229802847, 0.017400018870830536, 0.06010522320866585, 0.03949521854519844, -0.0017327496316283941, 0.0772835910320282, 0.014559631235897541, -0.002193329157307744, -0.0018453672528266907, 0.01501477137207985, 0.021672891452908516, 0.007331391330808401, 0.017999522387981415, 0.049744121730327606, 0.012588190846145153, -0.002632207004353404, 0.04346176236867905, 0.06297491490840912, 0.066607266664505, -0.03639739379286766, -0.038729604333639145, 0.0440126471221447, 0.005643433425575495, 0.00569261284545064, -0.034878481179475784, -0.07138055562973022, 0.10089902579784393, -0.02475632168352604, 0.014684424735605717, -0.025919567793607712, -0.07273474335670471, -0.01743425242602825, 0.0260188989341259, 0.11413373798131943, -0.07092969864606857, 0.018040649592876434, -0.0033645096700638533, 0.008468223735690117, -0.0031982611399143934, 0.005925314966589212, -0.022993477061390877, 0.07761327922344208, 0.034725937992334366, 0.08739188313484192, 0.046260979026556015, 0.018758729100227356, 0.01104747410863638, -0.045824144035577774, -0.046474333852529526, 0.026539461687207222, 0.07402202486991882, 0.06560054421424866, 0.06272173672914505, 0.07237668335437775, -0.008960521779954433, -0.03532486408948898, -0.005384554620832205, -0.00321886595338583, -0.03802550584077835, -0.04136472940444946, -0.09670209884643555, 0.04421926662325859, -0.033506348729133606, -0.07136601209640503, -0.01164277270436287, -0.0071111866272985935, 0.0006453522946685553, -0.0883803591132164, -0.11334278434515, -0.12120428681373596, -0.0013210743200033903, -0.044243115931749344, -0.08665943145751953, 3.997687309833669e-33, 0.025276146829128265, -0.0026350223924964666, -0.0811300128698349, 0.025461891666054726, 0.0013292640214785933, 0.016038043424487114, 0.09549155831336975, 0.03321702778339386, -0.012048881500959396, 0.016985641792416573, -0.08307890594005585, -0.12452162057161331, 0.043909598141908646, 0.012151088565587997, 0.06574593484401703, 0.10052959620952606, 0.07295705378055573, -0.026920240372419357, -0.032184794545173645, -0.053466908633708954, -0.12637238204479218, 0.005398075561970472, -0.035390958189964294, -0.0042800139635801315, -0.025039484724402428, 0.04162561893463135, -0.09993349015712738, -0.047652728855609894, -0.023976044729351997, 0.0026398205664008856, -0.055191028863191605, 0.013548431918025017, 0.04904065281152725, 0.08499688655138016, -0.042024578899145126, 0.07673399895429611, 0.03321308642625809, 0.0012652842560783029, 0.03999503701925278, 0.06455167382955551, -0.04337263107299805, -0.04965050518512726, 0.05795806273818016, 0.1126786470413208, 0.07069910317659378, 0.008226494304835796, 0.04381539300084114, -0.022527894005179405, -0.007248694077134132, 0.04985775798559189, 0.0386049821972847, 0.06791184097528458, -0.04107007011771202, 0.00573221780359745, 0.017908034846186638, 0.049305785447359085, -0.051455240696668625, 0.05103078857064247, -0.09380978345870972, -0.06816752254962921, 0.0652628019452095, 0.075457364320755, -0.016841884702444077, 0.06612507998943329, -0.0028971072752028704, -0.020738182589411736, -0.1270085871219635, 0.06160474941134453, -0.009813203476369381, -0.01470610685646534, 0.13544604182243347, 0.03413686528801918, -0.06481856107711792, 0.051017045974731445, -0.06637555360794067, 0.02918831817805767, 0.07939160615205765, 0.014440285973250866, -0.027310043573379517, 0.005267069209367037, -0.06761956959962845, -0.020494425669312477, -0.027144689112901688, -0.02614976093173027, -0.07054668664932251, 0.034717950969934464, 0.0076125310733914375, -0.10216671228408813, 0.058427829295396805, -0.074785977602005, -0.02196802943944931, -0.0068086981773376465, -0.05130331590771675, -0.036969855427742004, 0.025690186768770218, -1.7501509574913143e-08, 0.06809660792350769, 0.045000918209552765, -0.044086355715990067, 0.012878754176199436, -0.05775947868824005, -0.09547640383243561, 0.06219944357872009, -0.00427264953032136, -0.008670204319059849, 0.0002549805794842541, -0.07361151278018951, 0.056062184274196625, -0.06970256567001343, -0.051116280257701874, -0.04102284461259842, -0.004761006683111191, -0.03246322274208069, 0.04304736852645874, 0.0086831608787179, 0.022707797586917877, -0.0049053519032895565, 0.02335800603032112, -0.045639410614967346, -0.05810333043336868, 0.012541485950350761, -0.09903227537870407, 0.040629226714372635, 0.04566892236471176, 0.002715927315875888, -0.005313064903020859, 0.0664028748869896, -0.027287553995847702, -0.05007484182715416, -0.09029503166675568, -0.03612228110432625, 0.012680095620453358, -0.0058304425328969955, -0.005093271844089031, 0.00950753502547741, -0.02905246615409851, 0.09497947990894318, 0.06199067085981369, 0.01253666914999485, -0.011961053125560284, 0.02452567033469677, 0.04538300633430481, 0.05382111296057701, -0.035177163779735565, 0.11464710533618927, -0.0890202596783638, -0.1114850714802742, 0.09941161423921585, 0.003938883543014526, 0.004478378687053919, 0.003446623682975769, 0.07089641690254211, -0.051293663680553436, -0.012674185447394848, 0.02187473140656948, -0.02001197449862957, -0.014911333099007607, 0.04920436814427376, 0.08929191529750824, -0.011127757839858532]\n"
     ]
    }
   ],
   "source": [
    "# Pre download the embedding model, LangChain download bug\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    encode_kwargs={\"normalize_embeddings\": True}\n",
    "    )\n",
    "\n",
    "test = \"What is the capital of France?\"\n",
    "test_embedding = embeddings.embed_query(test)\n",
    "print(test_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f6a15a",
   "metadata": {},
   "source": [
    "3.2 Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb9e933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Programmed cell' metadata={'id': 21645374}\n",
      "page_content='cell death (PCD) is' metadata={'id': 21645374}\n",
      "page_content='death (PCD) is the' metadata={'id': 21645374}\n",
      "page_content='is the regulated' metadata={'id': 21645374}\n",
      "page_content='the regulated death' metadata={'id': 21645374}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # Set a really small chunk size, just to show.\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=20,\n",
    ")\n",
    "\n",
    "metadatas = [{\"id\": idx} for idx in documents.index]\n",
    "texts = text_splitter.create_documents(documents.abstract.tolist(), metadatas=metadatas)\n",
    "#print(texts[0])\n",
    "# print(texts[1])\n",
    "# print(texts[2])\n",
    "# print(texts[3])\n",
    "# print(texts[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ee665d",
   "metadata": {},
   "source": [
    "Step 3.3: Define a vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5d556f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = Chroma.from_documents(\n",
    "    documents=texts,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=\"./chroma_db\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da1b89ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* [SIM=1.031361] Kuopio province, on [{'id': 15841770}]\n",
      "* [SIM=1.061872] of Kaohsiung, [{'id': 28359277}]\n",
      "* [SIM=1.083274] Kaohsiung, Taiwan [{'id': 28359277}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Sanity check, Chroma uses L2-score by default so scores closer to 0 means that its a good match\n",
    "results = vector_store.similarity_search_with_score(\n",
    "    \"Bajsapa?\", k=3\n",
    ")\n",
    "for res, score in results:\n",
    "    print(f\"* [SIM={score:3f}] {res.page_content} [{res.metadata}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27633d9",
   "metadata": {},
   "source": [
    "### Step 4: Define the full RAG pipeline (Option B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c27665c",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever()\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (A4 venv)",
   "language": "python",
   "name": "a4_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
